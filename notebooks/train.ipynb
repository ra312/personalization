{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"has_seen_venue_in_this_session\"\n",
    "pred_label = f\"pred_{label_column}\"\n",
    "group_column = \"session_id_hashed\"\n",
    "rank_column = \"popularity\"\n",
    "rank_pos_column = \"position_in_list\"\n",
    "predicted_rank_column = f\"predicted_{rank_column}\"\n",
    "features = [\n",
    "    'venue_id',\n",
    "    'conversions_per_impression',\n",
    "    'price_range',\n",
    "    'rating',\n",
    "    'popularity',\n",
    "    'retention_rate',\n",
    "    'session_id_hashed',\n",
    "    'position_in_list',\n",
    "    #  'has_seen_venue_in_this_session',\n",
    "    #  'is_new_user',\n",
    "    'is_from_order_again',\n",
    "    'is_recommended']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_boolean_to_int(ranking_data):\n",
    "    bool_cols = ranking_data.select(pl.col(pl.Boolean)).columns\n",
    "    ranking_data = ranking_data.with_columns(\n",
    "        [\n",
    "            pl.col(column).cast(pl.Int8, strict=False).alias(column)\n",
    "            for column in bool_cols\n",
    "            ]\n",
    "        )\n",
    "    return ranking_data\n",
    "def plot_lgb_report(lgb_model, evals_logs: dict, eval_at = [10, 20, 40]):\n",
    "    for k in eval_at:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        lgb.plot_metric(evals_logs, ax=ax, metric=f\"ndcg@{k}\")\n",
    "\n",
    "        \n",
    "    lgb.plot_importance(lgb_model, importance_type=\"gain\", figsize=(14, 8))\n",
    "    lgb.plot_importance(lgb_model, importance_type=\"split\", figsize=(14, 8))\n",
    "        \n",
    "def qa_features(model: lgb, features: List[str]):\n",
    "    feature_importance = {\n",
    "        feature: importance\n",
    "        for feature, importance in zip(\n",
    "        model.feature_name(), model.feature_importance()\n",
    "        )\n",
    "    }\n",
    "    print(feature_importance)\n",
    "    used_features = [\n",
    "        f for f in feature_importance\n",
    "        if feature_importance[f] != 0\n",
    "    ]\n",
    "    dropped_features = [f for f in features if f not in used_features]\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Used features: \")\n",
    "    print(used_features)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\n",
    "        f\"passed {len(features)} \"\n",
    "        f\"features and model used {len(used_features)} of them\"\n",
    "    )\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"these features were dropped: {dropped_features}\")\n",
    "    return used_features\n",
    "\n",
    "def generate_predictions(\n",
    "    test_set: pl.DataFrame, model: lgb, features_to_use: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    test_set_pandas = test_set.sort(\n",
    "        by=[group_column, rank_column], reverse=False\n",
    "    ).to_pandas()\n",
    "    test_set_pandas[features_to_use] = test_set_pandas[features_to_use].fillna(0)\n",
    "    test_x = test_set_pandas[features_to_use]\n",
    "\n",
    "    test_set_pandas[pred_label] = model.predict(test_x)\n",
    "    test_set_pandas[predicted_rank_column] = (\n",
    "        test_set_pandas.groupby(group_column)[pred_label]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "    )\n",
    "    return test_set_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sessions = pl.read_csv(\"../sessions.csv\")\n",
    "sessions = sessions.drop_nulls()\n",
    "venues = pl.read_csv(\"../venues.csv\")\n",
    "venues = venues.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_purchase_indicator_for_session(sessions):\n",
    "    sessions = sessions.join(sessions.groupby(\"session_id\").agg(\n",
    "        pl.col('purchased').max().alias('purchased_in_session')\n",
    "    ).select('session_id','purchased_in_session'), on='session_id').sort('purchased_in_session')\n",
    "    return sessions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join venue data with search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_data = sessions.join(venues, on=\"venue_id\")\n",
    "ranking_data = convert_boolean_to_int(ranking_data)\n",
    "# hex_string = \"0a21dde9-1495-417c-bb9d-9922b81f2e6a\"\n",
    "\n",
    "\n",
    "ranking_data = ranking_data.with_column(\n",
    "    pl.col(\"session_id\").str.replace(\"-\",\"\").alias(\"session_id_hashed\").hash(seed=0)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, unseen_set = train_test_split(ranking_data, train_size=0.2, test_size=0.8)\n",
    "val_set, test_set = train_test_split(unseen_set, train_size=0.2, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape, val_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.sort(by=[group_column, rank_column], reverse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.sort(by=[group_column, rank_column], reverse=False)\n",
    "train_set_group_sizes = (\n",
    "    train_set.groupby(group_column)\n",
    "    .agg(pl.col(group_column).count().alias(\"count\"))\n",
    "    .sort(group_column)\n",
    "    .select(\"count\")\n",
    ")\n",
    "\n",
    "val_set = val_set.sort(by=[group_column, rank_column], reverse=False)\n",
    "val_set_group_sizes = (\n",
    "    val_set.groupby(group_column)\n",
    "    .agg(pl.col(group_column).count().alias(\"count\"))\n",
    "    .sort(group_column)\n",
    "    .select(\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_y = train_set[[label_column]]\n",
    "train_x = train_set[features]\n",
    "\n",
    "val_y = val_set[[label_column]]\n",
    "val_x = val_set[features]\n",
    "\n",
    "test_x = test_set[features]\n",
    "\n",
    "lgb_train_set = lgb.Dataset(\n",
    "    train_x.to_pandas(),\n",
    "    label=train_y.to_pandas(),\n",
    "    group=train_set_group_sizes.to_numpy(),\n",
    "    free_raw_data=True\n",
    ").construct()\n",
    "\n",
    "lgb_valid_set = lgb.Dataset(\n",
    "    val_x.to_pandas(),\n",
    "    label=val_y.to_pandas(),\n",
    "    group=val_set_group_sizes.to_numpy(),\n",
    "    reference=lgb_train_set,\n",
    "    free_raw_data=True\n",
    ").construct()\n",
    "\n",
    "# some memory management\n",
    "# del train_set\n",
    "# del val_set\n",
    "del train_y\n",
    "del train_x\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(ranking_data[label_column].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path: str = \"/tmp/lgb_train_set.binary\"\n",
    "n_rows: int = lgb_train_set.num_data()\n",
    "n_features: int = lgb_train_set.num_feature()\n",
    "\n",
    "print(f\"Number of rows: {n_rows}\")\n",
    "\n",
    "\n",
    "print(f\"Number of columns: {n_features}\")\n",
    "os.system(f\"rm -rf {data_path}\")\n",
    "lgb_train_set.save_binary(data_path)\n",
    "# Define the path to the binary file\n",
    " \n",
    "import pathlib\n",
    "\n",
    "# Create a Path object from a string\n",
    "my_path = pathlib.Path(data_path)\n",
    "\n",
    "# Print the Path object\n",
    "print(my_path)\n",
    "\n",
    "# Load the dataset from the binary file\n",
    "dataset = lgb.Dataset(my_path, free_raw_data=False).construct()\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Number of rows: {dataset.num_data()}\")\n",
    "print(f\"Number of columns: {dataset.num_feature()}\")\n",
    "assert dataset.num_data() == n_rows\n",
    "assert dataset.num_feature() == n_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"num_leaves\": 100,\n",
    "    \"min_sum_hessian_in_leaf\": 10,\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [10, 20, 40],\n",
    "    \"learning_rate\": 0.8,\n",
    "    \"force_row_wise\": True,\n",
    "    \"num_iterations\": 10,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evals_logs = {}\n",
    "lgb_params\n",
    "lgb_model = lgb.train(\n",
    "    params=lgb_params,\n",
    "    train_set=lgb_train_set,\n",
    "    valid_sets=[lgb_valid_set, lgb_train_set],\n",
    "    valid_names=[\"val\", \"train\"],\n",
    "    verbose_eval=25,\n",
    "    evals_result=evals_logs,\n",
    "    early_stopping_rounds=25\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lgb_report(lgb_model, evals_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = qa_features(lgb_model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgb_model.save_model(\"/tmp/venues_ranking.pkl\")\n",
    "joblib.dump(lgb_model, 'rate_venues.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ranking_data\n",
    "    # .filter(pl.col(\"session_id_hashed\")==2697534841382868)\n",
    "    .sort(by=[group_column, rank_column], reverse=False)\n",
    "    .groupby(\"session_id\")\n",
    "    .agg(\n",
    "        pl.all().take([0,1, 2])\n",
    "    )\n",
    "    .explode(\"rating\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_score(y_true: pl.Series, y_pred:pl.Series):\n",
    "    return pl.Series([ndcg_score(y_true=y_true, y_score=y_pred)], dtype=pl.Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generate_predictions(test_set, lgb_model, features_to_use=features)\n",
    "predictions_pl = pl.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"has_seen_venue_in_this_session\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sessions_with_no_interactions(ranking_data):\n",
    "    active_sessions = (\n",
    "        ranking_data\n",
    "        .filter(pl.col(label_column)==1)\n",
    "        .select(\"session_id\",\"position_in_list\", \"popularity\").sort(\"session_id\").groupby(\"session_id\").count().sort(\"count\")\\\n",
    "        .filter(pl.col(\"count\")>1).select(\"session_id\")\n",
    "    )\n",
    "    active_ranking_data = ranking_data.join(active_sessions, on=\"session_id\")\n",
    "\n",
    "    return active_ranking_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ranking_data = drop_sessions_with_no_interactions(predictions_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def my_ndcg(y_true, y_pred):\n",
    "    y_true = np.asarray([y_true])\n",
    "    y_pred = np.asarray([y_pred])\n",
    "    return ndcg_score(y_true=y_true, y_score = y_pred)\n",
    "def my_relative_percentage_diff(baseline_value, model_value):\n",
    "    baseline_vector = np.asarray(baseline_value)\n",
    "    model_vector = np.asarray(model_value)\n",
    "    print(baseline_vector)\n",
    "    print(model_vector)\n",
    "    return abs(baseline_vector-model_vector)/baseline_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "baseline_ndcg_per_sessions = (\n",
    "    active_ranking_data\n",
    "    .filter(pl.col(label_column)==1)\n",
    "    .groupby(\"session_id\")\n",
    "    .agg([\n",
    "        pl.apply(\n",
    "            [pl.col('position_in_list'), pl.col(\"popularity\")], lambda s: my_ndcg(s[0],s[1]) ).alias('baseline_ndcg')\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_ndcg_per_sessions = (\n",
    "    active_ranking_data\n",
    "    .filter(pl.col(label_column)==1)\n",
    "    .groupby(\"session_id\")\n",
    "    .agg([\n",
    "        pl.apply(\n",
    "            [pl.col('position_in_list'), pl.col(\"predicted_popularity\")], lambda s: my_ndcg(s[0],s[1]) ).alias('model_ndcg')\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_columns = [\"baseline_ndcg\", \"model_ndcg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dataframe = predictions_pl.join(baseline_ndcg_per_sessions, on=\"session_id\").join(model_ndcg_per_sessions, on=\"session_id\")[ used_features + metric_columns].with_columns(\n",
    "    [\n",
    "        (pl.col(\"model_ndcg\")-pl.col(\"baseline_ndcg\")).alias(\"ndcg_diff\")\n",
    "    ]\n",
    ").groupby(\"venue_id\").mean()\n",
    "metric_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate percentage increase of ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dataframe.with_columns(\n",
    "    \n",
    "\n",
    "    (abs(pl.col('baseline_ndcg') - pl.col(\"model_ndcg\"))/pl.col('baseline_ndcg') * 100).alias('perc_increase_in_ndcg')\n",
    "    \n",
    ").groupby('venue_id').agg(\n",
    "    pl.col('perc_increase_in_ndcg').mean()\n",
    ").sort('perc_increase_in_ndcg', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rating_venues = metric_dataframe.with_columns(\n",
    "    \n",
    "\n",
    "    (abs(pl.col('baseline_ndcg') - pl.col(\"model_ndcg\"))/pl.col('baseline_ndcg') * 100).alias('perc_increase_in_ndcg')\n",
    "    \n",
    ").groupby('venue_id').agg(\n",
    "    pl.col('perc_increase_in_ndcg').mean()\n",
    ").sort('perc_increase_in_ndcg', reverse=True).head(5).select('venue_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_data.join(highest_rating_venues, on ='venue_id')[features].head(10).to_pandas().to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":3352618370338455358,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},{\"venue_id\":-8608196287932575311,\"conversions_per_impression\":0.1206581353,\"price_range\":1,\"rating\":9.2,\"popularity\":0.2022771056,\"retention_rate\":0.18,\"session_id_hashed\":4664838061955502305,\"position_in_list\":0,\"is_from_order_again\":0,\"is_recommended\":0},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":1006495267592422768,\"position_in_list\":0,\"is_from_order_again\":0,\"is_recommended\":0},{\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":16271107337218474123,\"position_in_list\":31,\"is_from_order_again\":0,\"is_recommended\":0},{\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":12992628493413309367,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},{\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":11792925231034451836,\"position_in_list\":13,\"is_from_order_again\":1,\"is_recommended\":1},{\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":2327279187342959944,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},{\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":6669153405411707628,\"position_in_list\":33,\"is_from_order_again\":1,\"is_recommended\":0},\n",
    "    {\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":3159537071444654512,\"position_in_list\":5,\"is_from_order_again\":0,\"is_recommended\":0},{\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":13008284017370400506,\"position_in_list\":31,\"is_from_order_again\":1,\"is_recommended\":1}]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore predicted rankings on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_total = predictions_pl.select('venue_id').unique()\n",
    "venues_total.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pl[features + [pred_label, predicted_rank_column]].filter(pl.col(pred_label)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_predictions = predictions_pl[features + [pred_label, predicted_rank_column]].filter(pl.col(pred_label)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pl.groupby('venue_id').agg(\n",
    "    [\n",
    "        pl.col(rank_column).max().alias(f\"max_{rank_column}\"),\n",
    "        pl.col(rank_column).min().alias(f\"min_{rank_column}\"),\n",
    "        pl.col(rank_column).quantile(0.8).alias(f\"q80_{rank_column}\"),\n",
    "        pl.col(predicted_rank_column).max().alias(f\"max_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).min().alias(f\"min_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).quantile(0.8).alias(f\"q80_{predicted_rank_column}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_predictions.groupby('venue_id').agg(\n",
    "    [\n",
    "        pl.col(rank_column).max().alias(f\"max_{rank_column}\"),\n",
    "        pl.col(rank_column).min().alias(f\"min_{rank_column}\"),\n",
    "        pl.col(rank_column).quantile(0.8).alias(f\"q80_{rank_column}\"),\n",
    "        pl.col(predicted_rank_column).max().alias(f\"max_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).min().alias(f\"min_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).quantile(0.8).alias(f\"q80_{predicted_rank_column}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_data[rank_column].min(), ranking_data[rank_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_predictions.groupby('venue_id').agg(\n",
    "    [\n",
    "        pl.col(rank_column).max().alias(f\"max_{rank_column}\"),\n",
    "        pl.col(rank_column).min().alias(f\"min_{rank_column}\"),\n",
    "        pl.col(rank_column).quantile(0.8).alias(f\"q80_{rank_column}\"),\n",
    "        pl.col(predicted_rank_column).max().alias(f\"max_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).min().alias(f\"min_{predicted_rank_column}\"),\n",
    "        pl.col(predicted_rank_column).quantile(0.8).alias(f\"q80_{predicted_rank_column}\")]\n",
    ").select(f\"q80_{predicted_rank_column}\", f\"q80_{rank_column}\").to_pandas().max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# percentage of venues where we predict popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "926/1043 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pl[features + [pred_label, predicted_rank_column]].filter(pl.col(pred_label)>0).select(\"venue_id\", predicted_rank_column).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(\n",
    "    test_set: pl.DataFrame, model: lgb, features_to_use: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    test_set_pandas[features_to_use] = test_set_pandas[features_to_use].fillna(0)\n",
    "    test_x = test_set_pandas[features_to_use]\n",
    "\n",
    "    test_set_pandas[pred_label] = model.predict(test_x)\n",
    "    test_set_pandas[predicted_rank_column] = (\n",
    "        test_set_pandas.groupby(group_column)[pred_label]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "    )\n",
    "    return test_set_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import json\n",
    "def generate_model_ratings(\n",
    "    test_incoming_inference_features: str, lgb_model: Any, pred_label=\"has_seen_venue_in_this_session\", predicted_rank_column=\"predicted_popularity\", group_column=\"session_id_hashed\"\n",
    "    ) -> str:\n",
    "    inference_dataframe = pl.DataFrame(json.loads(test_incoming_inference_features))\n",
    "    incoming_features = inference_dataframe.columns\n",
    "    expected_features = lgb_model.feature_name()\n",
    "    assert all(expected_column == actual_column for expected_column, actual_column in zip(incoming_features, expected_features)),\\\n",
    "        \"the inference feature do not have the same order as the training features, this can lead to poorer performance\"\n",
    "    inference_dataframe_pd = inference_dataframe.sort(\n",
    "        by=[group_column, rank_column], reverse=False\n",
    "    ).to_pandas()\n",
    "    inference_dataframe_pd[pred_label] = lgb_model.predict(inference_dataframe_pd)\n",
    "    inference_dataframe_pd[predicted_rank_column] = (\n",
    "        inference_dataframe_pd.groupby(group_column)[pred_label]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "    )\n",
    "    predictions_pl = pl.DataFrame(inference_dataframe_pd)\n",
    "    return predictions_pl.groupby('venue_id').agg(\n",
    "    [\n",
    "        pl.col(predicted_rank_column).quantile(0.8).alias(f\"q80_{predicted_rank_column}\")]\n",
    "    ).select(\"venue_id\", f\"q80_{predicted_rank_column}\").to_pandas().head(5).to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_incoming_inference_features = '''[\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":3352618370338455358,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},\n",
    "    {\"venue_id\":-8608196287932575311,\"conversions_per_impression\":0.1206581353,\"price_range\":1,\"rating\":9.2,\"popularity\":0.2022771056,\"retention_rate\":0.18,\"session_id_hashed\":4664838061955502305,\"position_in_list\":0,\"is_from_order_again\":0,\"is_recommended\":0},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":1006495267592422768,\"position_in_list\":0,\"is_from_order_again\":0,\"is_recommended\":0},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":16271107337218474123,\"position_in_list\":31,\"is_from_order_again\":0,\"is_recommended\":0},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":12992628493413309367,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},\n",
    "    {\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":11792925231034451836,\"position_in_list\":13,\"is_from_order_again\":1,\"is_recommended\":1},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":2327279187342959944,\"position_in_list\":0,\"is_from_order_again\":1,\"is_recommended\":0},\n",
    "    {\"venue_id\":-4202398962129790175,\"conversions_per_impression\":0.3556765815,\"price_range\":1,\"rating\":8.6,\"popularity\":4.4884057024,\"retention_rate\":0.5884095,\"session_id_hashed\":6669153405411707628,\"position_in_list\":33,\"is_from_order_again\":1,\"is_recommended\":0},\n",
    "    {\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":3159537071444654512,\"position_in_list\":5,\"is_from_order_again\":0,\"is_recommended\":0},\n",
    "    {\"venue_id\":8968794542286256815,\"conversions_per_impression\":0.4036363636,\"price_range\":1,\"rating\":8.8,\"popularity\":0.8977682883,\"retention_rate\":0.272727,\"session_id_hashed\":13008284017370400506,\"position_in_list\":31,\"is_from_order_again\":1,\"is_recommended\":1}]\n",
    "'''.replace('\\n','').replace(' ','')\n",
    "generate_model_ratings(test_incoming_inference_features, lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    server = InferenceServer(name=\"test-server\")\n",
    "    data = [[1424193000929084737, 0.403492, 1, 8.6, 5.537811, 0.384965, 0, 1, 0],\n",
    "            [1424193000929084736, 0.403492, 1, 8.6, 5.537811, 0.384965, 0, 1, 0],\n",
    "            [1424193000929084735, 0.403492, 1, 8.6, 5.537811, 0.384965, 0, 1, 0],\n",
    "            [1424193000929084734, 0.403492, 1, 8.6, 5.537811, 0.384965, 0, 1, 0]]\n",
    "\n",
    "    real_response = requests.get(\"http://localhost:8000/predict\", json=data)\n",
    "    expected_response = {\n",
    "    \"venue_id\": [1424193000929084737, 1424193000929084736, 1424193000929084735, 1424193000929084734],\n",
    "    \"has_seen_venue_in_this_session\": [0.0, 0.0, 0.0, 0.0]\n",
    "    }\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalization",
   "language": "python",
   "name": "personalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d9503d5d1b39f5fd50696c7a12c634571ed96840cbc04e858eb22631f8b639d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
